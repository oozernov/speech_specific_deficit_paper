---
title: "select_tone_paper"
author: "Ola Ozernov-Palchik"
date: "11/1/2020"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Adult Analysis

## Load packages and organize data 

```{r, include=FALSE, echo=FALSE}
Packages <- c("dplyr", "readr", "magrittr", "tidyr", "ggplot2", "lme4", "lmerTest",
              "emmeans", "sjstats","dabestr","gridExtra",'knitr','psych',
              'lmPerm',"lavaan",'MASS','tidyverse','psych','mice',"rstatix")
lapply(Packages, library, character.only = TRUE)

#dir<-dirname(rstudioapi::getActiveDocumentContext()$path)
#setwd("dir")

#d=read.csv("data/ABCD_data072320.csv")
d=read.csv("data/abcd_beh_122020.csv")

groups=read.csv("data/abcd_group.csv")
snr=read.csv("data/SNR.csv")
music=read.csv("data/ABCD_music_data.csv")
tone=read.csv("data/tone_jnd_ntd_122020.csv")
sa=read.csv("data/dys_comp_selec_adapt_122020.csv")
tone_sa=merge(tone,sa)
accuracy<-read.csv("sa_accuracy.csv")

music$music_y_n<-ifelse(music$music_y_n == 'Yes',1,0) 
music$music_y_n<-as.factor(music$music_y_n)

names(music)[names(music)=="ABCD.ID"] <- "PartID"
names(groups)[names(groups)=="ID"] <- "PartID"
names(d)[names(d)=="abcd_id"] <- "PartID"
d$PA<-(rowMeans(d[c('ctopp_elision_ss_2','ctopp_blending_ss_2','ctopp_nonword_ss_2')], na.rm=TRUE))
d$WID<-(rowMeans(d[c('wrmt_id_ss','wrmt_wa_ss','towre_pde_ss','towre_sw_ss')], na.rm=TRUE))

d=merge(d,groups,
        by='PartID',all=TRUE)
d=merge(d,tone_sa,'PartID',all=TRUE)
d=merge(d,accuracy,'PartID',all=TRUE)

#d=merge(d,snr,'PartID',all=FALSE)
d_m=merge(d,music,'PartID',all=TRUE)

#names(d)[names(d)=="m_jnd"] <- "tone_thresh"
names(d)[names(d)=="slope"] <- "m_slope"
names(d)[names(d)=="d"] <- "select_sloped"
names(d)[names(d)=="adapt"] <- "adaptor_diff"
#names(d)[names(d)=="m_fd_hz"] <- "ntd"


```
```{r}
hist(d$adaptor_diff)
```

## Group beh differences
```{r, echo=FALSE}
table(d$Subgroup,d$background_sex)
beh_a<-d2%>%ungroup%>%dplyr::select(Subgroup,background_age,kbit_ss_2,wrmt_id_ss_2,wrmt_wa_ss_2,,towre_sw_ss_2,towre_pde_ss_2,ppvt_vocab_ss_2,gort_ori_ss_2,ctopp_blending_ss_2,ctopp_elision_ss_2,ctopp_nonword_ss_2,ran_2set_ss_2)

library(arsenal)
table_one <- tableby(Subgroup ~ ., data = beh_a)
summary(table_one, title = "Behavioral Data Adults")
beh_a %>% cohens_d(ctopp_nonword_ss_2~ Subgroup, var.equal = TRUE)
chisq.test(d2$Subgroup,d2$background_sex)

```

## Music Analysis 
```{r, echo=FALSE,include=FALSE}
hist(d_m$total_years)
table(d_m$music_y_n)
d_m2<-d_m %>%
  dplyr::filter(music_y_n=='1')
sd(d_m2$total_years)
d_group<-d2%>%dplyr::filter(Subgroup=="DD"|Subgroup=="TYP")
range(d_m$total_years)
t.test(d_group$tot_music~d_group$Subgroup.x)
tbl = table(d_group$music_y_n,d_group$Subgroup.x)
tbl
chisq.test(tbl)
anova(lm(tone_thresh~music_y_n+Subgroup.x, data=d_group)) #group differences sig after PA and SNR partialed out
anova(lm(m_slope~music_y_n+Subgroup.x, data=d_group)) #group differences sig after PA and SNR partialed out
anova(lm(diff_8~music_y_n+Subgroup.x, data=d_group)) #group differences sig after PA and SNR partialed out
anova(lm(ntd~music_y_n+Subgroup.x, data=d_group)) #group differences sig after PA and SNR partialed out
summary(lm(ctopp_blending_ss~select_sloped,data=d))

```
### Adult: Correlations
```{r,echo=FALSE}


d_a3<-d%>%filter(age.x=='Adult')%>% dplyr::select(adaptor_diff,m_slope,PA,tone_thresh,ntd)

resa <- cor(na.omit(d_a3,method = "pearson"))
#d_a3<-na.omit(d_a3)%>%filter(adaptor_diff!='Inf'& adaptor_diff>-4.7)

#create a table with r and p
source("corstars_function.R")
corstars(d_a3,method="pearson")#you need to run the function first
```

###Adult: Correlations by group-TYP
```{r,echo=FALSE}
dd<-d%>%filter(age.x=='Adult')%>%dplyr::filter(Subgroup=='DD')
dd<-na.omit(dd%>%ungroup() %>% dplyr::select(adaptor_diff,m_slope,PA,tone_thresh,ntd))

typ<-d%>%filter(age.x=='Adult')%>%filter(Subgroup=='TYP')
typ<-na.omit(typ%>%ungroup() %>% dplyr::select(adaptor_diff,m_slope,PA,tone_thresh,ntd))
corstars(typ,method="pearson")#you need to run the function first
```

###Adult: Correlations by group-DYS
```{r,echo=FALSE}

corstars(dd,method="pearson")#you need to run the function first
```

### Adult: Mediation Analysis
```{r,echo=FALSE}
#check assumptions

d_a3 %>% ungroup %>% 
  dplyr::select(tone_thresh, m_slope, PA,adaptor_diff) %>% 
  pairs.panels()


#check variance
varTable(d_a3)

#d2$m_slope<-log10(d3$m_slope)

#http://lavaan.ugent.be/tutorial/mediation.html
#https://nmmichalak.github.io/nicholas_michalak/blog_entries/2018/nrg01/nrg01.html
```

#### Model 1 JND
```{r,echo=FALSE}
###H1: #Y=PA, X=tone threshold, M=slectAdapt slope

model_h1<-'#direct effect
  PA~c*tone_thresh
#mediator
  m_slope~a*tone_thresh
  PA~b*m_slope
# indirect effect (a*b)
  ab := a*b
# total effect
  total := c + (a*b)'

#run mediation analysis with bootstrapping
fit_h1<-lavaan::sem(model_h1, data=d_a3,bootstrap=10000)
summary(fit_h1,fit.measures=T, rsq=T)

#created bootsrapped confidence intervals
boot.fit_h1<-lavaan::parameterEstimates(fit_h1, boot.ci.type = "bca.simple",level = 0.95, 
                             ci=TRUE,pval=TRUE,standardized = FALSE)
boot.fit_h1

library(psych)
m1<-psych::mediate(`Phonological awareness` ~ `Tone discrimination` + (`Categorical perception`), data=d2)
print(m1, digits=3) #to compare with Hayes
names(d2)[names(d2)=="tone_thresh"] <- "Tone discrimination"
names(d2)[names(d2)=="m_slope"] <- "Categorical perception"
names(d2)[names(d2)=="ntd"] <- "Tone anchoring"
names(d2)[names(d2)=="adaptor_diff"] <- "Speech adaptation"
names(d2)[names(d2)=="PA"] <- "Phonological_awareness"


mediate.diagram(m1, digits=2, main = "Adult")

```

#### Model 2 NTD
```{r,echo=FALSE}
d4<-d2%>%ungroup %>% dplyr::select(m_slope,ntd, PA)
d4<-na.omit(d4)
d4$m_slope<-log10(d4$m_slope)
### H2: Y=PA, X=ntd, M=slope
model_h2<-'#direct effect
  PA~c*ntd
#mediator
  m_slope~a*ntd
  PA~b*m_slope
# indirect effect (a*b)
  ab := a*b
# total effect
  total := c + (a*b)'

#run mediation analysis with bootstrapping
fit_h2<-lavaan::sem(model_h2, data=d4,bootstrap=10000)
summary(fit_h2,fit.measures=T, rsq=T)
boot.fit_h2<-lavaan::parameterEstimates(fit_h2, boot.ci.type = "bca.simple",level = 0.95,
                                        ci=TRUE,pval=TRUE,standardized = FALSE)
boot.fit_h2
```

#### Model 3 Adaptation

```{r,echo=FALSE}
### H3: Y=PA, X=adaptor_diff, M=select_adapt

model_h3<-'#direct effect
  PA~c*adaptor_diff
#mediator
  m_slope~a*adaptor_diff
  PA~b*m_slope
# indirect effect (a*b)
  ab := a*b
# total effect
  total := c + (a*b)'
#run mediation analysis with bootstrapping
fit_h3<-lavaan::sem(model_h3, data=d3,bootstrap=10000)
summary(fit_h3,fit.measures=T, rsq=T)
boot.fit_h3<-lavaan::parameterEstimates(fit_h3, boot.ci.type = "bca.simple",level = 0.95, 
                                      ci=TRUE,pval=TRUE,standardized = FALSE)
boot.fit_h3
```

## Adult Dyslexia Only

#### Adult Dys: Model 1 JND
```{r,echo=FALSE}
dd<-d3%>%filter(Subgroup=='DD')

###H1: #Y=PA, X=tone threshold, M=slectAdapt slope

model_h1<-'#direct effect
  PA~c*tone_thresh
#mediator
  m_slope~a*tone_thresh
  PA~b*m_slope
# indirect effect (a*b)
  ab := a*b
# total effect
  total := c + (a*b)'

#run mediation analysis with bootstrapping
fit_h1<-lavaan::sem(model_h1, data=dd,bootstrap=10000)
summary(fit_h1,fit.measures=T, rsq=T)

#created bootsrapped confidence intervals
boot.fit_h1<-lavaan::parameterEstimates(fit_h1, boot.ci.type = "bca.simple",level = 0.95, 
                                        ci=TRUE,pval=TRUE,standardized = FALSE)
boot.fit_h1
```
#### Adult Dys: Model 2 NTD
```{r,echo=FALSE}


### H2: Y=PA, X=ntd, M=select_adapt

model_h2<-'#direct effect
  PA~c*ntd
#mediator
  m_slope~a*ntd
  PA~b*m_slope
# indirect effect (a*b)
  ab := a*b
# total effect
  total := c + (a*b)'

#run mediation analysis with bootstrapping
fit_h2<-lavaan::sem(model_h2, data=dd,bootstrap=10000)
summary(fit_h2,fit.measures=T, rsq=T)
boot.fit_h2<-lavaan::parameterEstimates(fit_h2, boot.ci.type = "bca.simple",level = 0.95,
                                        ci=TRUE,pval=TRUE,standardized = FALSE)
boot.fit_h2
```
#### Adult Dys: Model 3 Adaptation

```{r,echo=FALSE}

### H3: Y=PA, X=adaptor_diff, M=select_adapt

model_h3<-'#direct effect
  PA~c*adaptor_diff
#mediator
  m_slope~a*adaptor_diff
  PA~b*m_slope
# indirect effect (a*b)
  ab := a*b
# total effect
  total := c + (a*b)'
#run mediation analysis with bootstrapping
fit_h3<-lavaan::sem(model_h3, data=dd,bootstrap=10000)
summary(fit_h3,fit.measures=T, rsq=T)
boot.fit_h3<-lavaan::parameterEstimates(fit_h3, boot.ci.type = "bca.simple",level = 0.95, 
                                        ci=TRUE,pval=TRUE,standardized = FALSE)
boot.fit_h3
```

# Child Analysis

## Child: Organize Data
```{r, echo=FALSE, include=FALSE}

d_c<-read.csv("data/ind_tone_selct_child_111120.csv")
Missing_patterns <-md.pattern(d_c)
Missing_patterns
beh_c<-read.csv("data/child_data.csv")
d_c$PartID[!(d_c$PartID %in% beh_c$PartID)] #READ_6103"
beh_c$PartID[!(beh_c$PartID %in% d_c$PartID)] 

set.seed(182)
init = mice(beh_c, maxit=0)
meth = init$method
predM = init$predictorMatrix
predM[, c("PartID")]=0
imputed = mice(beh_c, method=meth, predictorMatrix=predM, m=50)
imputed <- complete(imputed)
#apply(imputed,2,pMiss)
beh_c2<-imputed
str(beh_c2)
Missing_patterns <-md.pattern(beh_c2)
Missing_patterns

d_c2<-merge(d_c,beh_c2,"PartID")
Missing_patterns <-md.pattern(d_c2)
Missing_patterns

names(d_c2)[names(d_c2)=="m_fd"] <- "tone_thresh"
names(d_c2)[names(d_c2)=="b"] <- "select_slopeb"
names(d_c2)[names(d_c2)=="d"] <- "select_sloped"
names(d_c2)[names(d_c2)=="mean_diff"]<-"adaptor_diff"

d_c2$PA<-(rowMeans(d_c2[c('ctel','ctbw')]))
#d_c$WID<-(rowMeans(d_c2[c('WID','WWA','twse','tpde')], na.rm=TRUE))
hist(d_c2$adaptor_diff)

d_c2=d_c2%>% 
  dplyr::group_by(PartID)%>% 
  dplyr::summarize(m_slope = ((select_slopeb+select_sloped)/2))%>% #mean select adapt slope
  left_join(d_c2, by = "PartID") 

```
## Behavioral comparisons
```{r, echo=FALSE}
table(d_c2$gender,d_c2$group) #1=male, 2=female
beh_c3<-d_c2%>%ungroup%>%dplyr::select(group,age,KBITss,WID,WWA,twse,tpde,ppvt,gort_roi,ctbw,ctel,ran_2)

library(arsenal)
table_one <- tableby(group ~ ., data = beh_c)
summary(table_one, title = "Behavioral Data Child")
names(beh_c3)
beh_c3 %>% rstatix::cohens_d(KBITss~ group, var.equal = TRUE)
```

## Child Correlations
```{r,echo=FALSE}
d_c3<-d_c2%>%ungroup() %>% dplyr::select(adaptor_diff,m_slope,PA,tone_thresh,ntd)
d_c3<-na.omit(d_c3)

#you need to run the function first
source("corstars_function.R")
corstars(d_c3, method="pearson")
```

###Child Correlation by Group

#### Child Dys

```{r,echo=FALSE}
### by DYS group ###

d_dd_c<-d_c2%>%filter(group=='Dys')
d_dd_c$PartID<-NULL

d_dd_c2<-d_dd_c%>%dplyr::select(adaptor_diff,m_slope,PA,tone_thresh,ntd)
str(d_dd_c2)
resa <- cor(na.omit(d_dd_c2,method = "pearson"))
d_dd_c<-na.omit(d_dd_c2)
#create a table with r and p
corstars(d_dd_c2,method="pearson")#you need to run the function first

```
#### Plot NTD and PA in Child
```{r,echo=FALSE}
#what does the PA and NTD correlation look like
ggplot(d_dd_c2, aes(x = ntd, y = PA)) +
  stat_smooth (
    method = "glm",
    formula = y ~ x,
    # colour = "black",
    size = 1
  ) +
  geom_point(aes (size = 5)) +
  scale_shape_manual(values = c(1, 17)) +
  labs(x = "NTD", y = "PA") +
  theme(
    axis.title = element_text(family = "Trebuchet MS", size = 20),
    legend.position ="none",
    legend.text = element_blank(),
    legend.title = element_blank(),
    panel.background = element_rect(fill = "transparent", colour = NA), 
    plot.background = element_rect(fill = "transparent", colour = NA),
    axis.line = element_line(colour = "black"),
    axis.text.x = element_text(size = 15),
    axis.text.y = element_text(size = 15))


#try without outlier
test<-d_dd_c2%>%filter(d_dd_c2$PA>6)
corstars(test,method="pearson")#you need to run the function first
```

#### Child Typ
```{r,echo=FALSE}

### by TYP group ###
d_t_c<-d_c2%>%filter(group=='Typ')
d_t_c<-d_t_c%>%ungroup() %>% dplyr::select(adaptor_diff,m_slope,PA,tone_thresh,ntd)
resct <- cor(na.omit(d_t_c,method = "spearman"))
d_t_c2<-na.omit(d_t_c)
#create a table with r and p
corstars(d_t_c2,method="pearson")#you need to run the function first
```

## Child: Mediation Analysis
```{r,echo=FALSE}
#check assumptions
d_c4<-d_c2 %>% ungroup %>% 
  dplyr::select(tone_thresh, m_slope, PA,adaptor_diff,group) %>% 
  pairs.panels()
#d_c4<-d_c3%>%filter(tone_thresh<300) #remove an outlier
```

#### Child: Model 1 JND
```{r,echo=FALSE}

###H1: #Y=PA, X=tone threshold, M=slectAdapt slope
d_c_1=d_c2 %>% ungroup %>% 
  dplyr::select(tone_thresh, m_slope, PA)
d_c_1<-na.omit(d_c_1)

model_h1<-'#direct effect
  PA~c*tone_thresh
#mediator
  m_slope~a*tone_thresh
  PA~b*m_slope
# indirect effect (a*b)
  ab := a*b
# total effect
  total := c + (a*b)'

#run mediation analysis with bootstrapping
fit_c_h1<-lavaan::sem(model_h1, data=d_c_1,bootstrap=10000)
summary(fit_c_h1,fit.measures=T, rsq=T)

#created bootsrapped confidence intervals
boot.fit_h1<-lavaan::parameterEstimates(fit_c_h1, boot.ci.type = "bca.simple",level = 0.95, 
                                     ci=TRUE,pval=TRUE,standardized = FALSE)
boot.fit_h1
```
#### Child: Model 2 NTD
```{r,echo=FALSE}
### H2: Y=PA, X=ntd, M=select_adapt
d_c_2=d_c2 %>% ungroup %>% 
  dplyr::select(m_slope, ntd, PA)
d_c_2<-na.omit(d_c_2)

model_h2<-'#direct effect
  PA~c*ntd
#mediator
  m_slope~a*ntd
  PA~b*m_slope
# indirect effect (a*b)
  ab := a*b
# total effect
  total := c + (a*b)'

#run mediation analysis with bootstrapping
fit_h2<-lavaan::sem(model_h2, data=d_c_2,bootstrap=1000)
summary(fit_h2,fit.measures=T, rsq=T)
boot.fit_h2<-lavaan::parameterEstimates(fit_h2, boot.ci.type = "bca.simple",level = 0.95,
                                     ci=TRUE,pval=TRUE,standardized = FALSE)
boot.fit_h2
```
#### Child: Model 3 Adaptation
```{r,echo=FALSE}
###H3: #Y=PA, X=adaptor_diff, M=slectAdapt slope
d_c4=d_c2 %>% ungroup %>% 
  dplyr::select(adaptor_diff, m_slope, PA)
d_c4<-na.omit(d_c4)
model_c_h3<-'#direct effect
  PA~c*adaptor_diff
#mediator
  m_slope~a*adaptor_diff
  PA~b*m_slope
# indirect effect (a*b)
  ab := a*b
# total effect
  total := c + (a*b)'

fit_c_h3<-lavaan::sem(model_c_h3, data=d_c4,bootstrap=1000)
summary(fit_c_h3,fit.measures=T, rsq=T)
boot.fit_c_h3<-lavaan::parameterEstimates(fit_c_h3, boot.ci.type = "bca.simple",level = 0.95, 
                                        ci=TRUE,pval=TRUE,standardized = FALSE)
boot.fit_c_h3
```

## Child: Dyslexia only

#### Child DYS: Model 1 JND
```{r,echo=FALSE}
dd_c<-d_c2%>%filter(group=='Dys')
dd_c_1=dd_c %>% ungroup %>% 
  dplyr::select(tone_thresh, m_slope, PA)
dd_c_1<-na.omit(dd_c_1)

###H1: #Y=PA, X=tone threshold, M=slectAdapt slope

model_h1<-'#direct effect
  PA~c*tone_thresh
#mediator
  m_slope~a*tone_thresh
  PA~b*m_slope
# indirect effect (a*b)
  ab := a*b
# total effect
  total := c + (a*b)'

#run mediation analysis with bootstrapping
fit_c_h1<-lavaan::sem(model_h1, data=dd_c_1,bootstrap=10000)
summary(fit_c_h1,fit.measures=T, rsq=T)

#created bootsrapped confidence intervals
boot.fit_h1<-lavaan::parameterEstimates(fit_c_h1, boot.ci.type = "bca.simple",level = 0.95, 
                                        ci=TRUE,pval=TRUE,standardized = FALSE)
boot.fit_h1
```

#### Child DYS: Model 2 NTD
```{r,echo=FALSE}
### H2: Y=PA, X=ntd, M=m_slope
dd_c_2=dd_c %>% ungroup %>% 
  dplyr::select(ntd, m_slope, PA)
dd_c_2<-na.omit(dd_c_2)
model_h2<-'#direct effect
  PA~c*ntd
#mediator
  m_slope~a*ntd
  PA~b*m_slope
# indirect effect (a*b)
  ab := a*b
# total effect
  total := c + (a*b)'

#run mediation analysis with bootstrapping
fit_h2<-lavaan::sem(model_h2, data=dd_c_2,bootstrap=10000)
summary(fit_h2,fit.measures=T, rsq=T)
boot.fit_h2<-lavaan::parameterEstimates(fit_h2, boot.ci.type = "bca.simple",level = 0.95,
                                        ci=TRUE,pval=TRUE,standardized = FALSE)
boot.fit_h2
```

#### Child DYS: Model 3 Adaptation
```{r,echo=FALSE}

###H3: #Y=PA, X=adaptor_diff, M=slectAdapt slope

model_c_h3<-'#direct effect
  PA~c*adaptor_diff
#mediator
  m_slope~a*adaptor_diff
  PA~b*m_slope
# indirect effect (a*b)
  ab := a*b
# total effect
  total := c + (a*b)'

fit_c_h3<-lavaan::sem(model_c_h3, data=dd_c,bootstrap=1000)
summary(fit_c_h3,fit.measures=T, rsq=T)
boot.fit_c_h3<-lavaan::parameterEstimates(fit_c_h3, boot.ci.type = "bca.simple",level = 0.95, 
                                          ci=TRUE,pval=TRUE,standardized = FALSE)
boot.fit_c_h3
```

